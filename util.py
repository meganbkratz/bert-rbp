import os, re
import numpy as np
import scipy
from Bio import motifs, SeqIO
from Bio.Seq import Seq


def search_training_data(sequence_file, training_file):
    """Function for parts of an RNA sequence that are present in the training data."""
    matches = []
    with open(sequence_file, 'r') as f:
        for line in f.readlines():
            if line[0] == '>':
                target_chromosome, target_start, target_end = parse_dna_range(line)

    with open(training_file, 'r') as f:
        lines = f.readlines()

    for i, line in enumerate(lines):
        if line[0] == '>':
            p = re.compile('[\dMXY]+')
            m = p.findall(line)
            chromosome, start, end = m
            if chromosome == target_chromosome:
                start = int(start)
                end = int(end)
                length = end-start
                if target_start-length <= start <= target_end:
                    matches.append((line, lines[i+1]))
    return matches

class FastaParsingError(Exception):
    pass


def parse_dna_range(s):
    p = re.compile(r'chr[0-9MXY]+:[0-9]+-[0-9]+')
    m = p.search(s)
    if m is None:
        print(' --- Could not parse chr:start-end pattern from "%s"' % s)
        raise FastaParsingError(' --- Could not parse chr:start-end pattern from "%s"' % s)
    p2 = re.compile(r'[0-9MXY]+')
    chromosome, start, end = p2.findall(m.group())
    start = int(start)
    end = int(end)
    return (chromosome, start, end)

def find_fasta_file(prob_file):
    species_dir = os.path.dirname(os.path.dirname(prob_file))
    for f in os.listdir(species_dir):
        if f[-13:] == 'genomic.fasta' or f[-10:] == 'genomic.fa':
            return os.path.join(species_dir, f)
    print("Unable to find .fasta file for %s. Can't plot sequences" % prob_file)

def load_sequence(filename):


    splices = [x for x in SeqIO.parse(filename, 'fasta')]

    sequences = {}

    for splice in splices:
        dna = np.array([s for s in splice.seq])
        mask = np.char.isupper(dna)
        rna = dna[mask]
        indices = np.argwhere(mask)[:,0]

        chromosome, start, end = parse_dna_range(splice.description)
        sequences[splice.id] = {'sequence':rna, 'dna_indices':indices+start}

    return sequences


# Functions for analyzing models and finding the best threshold to use:
def load_performance_data(filename):
    """Loads data saved from create_roc_files.py - Returns a stats array where each row has (threshold, true_positives,
    false_positives, true_negatives, false_negatives, positives, negatives)
    """
    stats = np.genfromtxt(filename, delimiter=',', names=True, dtype=[float]+[int]*6)
    return stats


def fscore(TP, FP, FN, b=1):
    return (1 + b**2) * TP / ((1+b**2)*TP + (b**2 * FN) + FP)


def calculate_precision_recall_fscore(stats):
    """Given a stats array where each row has (threshold, true_positives, false_positives, true_negatives,
    false_negatives, positives, negatives) as generated by create_roc_files.py, return an array of
    (threshold, precision, recall, F1_score, F0.5_score, and F0.2_score.
    """
    data = np.zeros(100, dtype=[
        ('threshold', float),
        ('precision', float),
        ('recall', float),
        ('F1_score', float),
        ('F0.5_score', float),
        ('F0.2_score', float)
        ])

    for i, x in enumerate(stats):
        threshold, TP, FP, TN, FN, p, n = x
        if ((TP + FP) == 0):
            data[i]['precision'] = np.nan
        else:
            data[i]['precision'] = TP / (TP + FP)
        data[i]['threshold'] = threshold
        data[i]['recall'] = TP / (TP + FN)
        data[i]['F1_score'] = (2*TP) / (2*TP + FP + FN)
        data[i]['F0.5_score'] = fscore(TP, FP, FN, b=0.5)
        data[i]['F0.2_score'] = fscore(TP, FP, FN, b=0.2)

    return data


def find_valid_thresholds(metrics, min_precision=0.9, min_recall=0.1):
    """Return the subset of thresholds that meet the mininmum precision and recall specified."""
    data = metrics[metrics['precision'] >= min_precision]
    data = data[data['recall'] >= min_recall]
    return data


def get_threshold(stats, min_recall=0.9, min_precision=0.1, mode=None):

    if mode not in ['lowest', 'high_f0.2']:
        raise Exception("Please specify a mode for finding a threshold. Current options are: \'lowest' (return the \
            lowest valid threshold) and 'high_f0.2' (return the threshold with the highest f0.2 score that meets \
            recall/precision criteria)")

    metrics = calculate_precision_recall_fscore(stats)
    valids = find_valid_thresholds(metrics, min_precision=min_precision, min_recall=min_recall)

    if len(valids) == 0:
        return None

    if mode == 'lowest':
        return valids['threshold'].min()
    elif mode == 'high_f0.2':
        return valids[np.argwhere(valids['F0.2_score'] == valids['F0.2_score'].max()).flatten()]['threshold'][0]


# motif analysis functions

def load_motif(filename):
    with open(filename, 'r') as f:
        seqs = f.readlines()

    seqs = [s.strip('\n').replace('U', 'T') for s in seqs]

    m = motifs.create(seqs)
    bg = {'A':0.3, 'C':0.2, 'G':0.2, 'T':0.3}
    m.background = bg
    m.pseudocounts = bg

    return m


def search_sequence_for_motif(motif, sequence):
    results = list(motif.pssm.search(sequence, threshold=3))

    return [r[0] for r in results]


if __name__ == "__main__":

    sequence_file = '/home/megan/work/lnc_rna/data/sequences/TARDBP/Tardbp-human_genomic.fasta'
    pos_training_file = '/home/megan/work/lnc_rna/code/bert-rbp/RBP_training_data/TARDBP.positive.fa'
    neg_training_file = '/home/megan/work/lnc_rna/code/bert-rbp/RBP_training_data/TARDBP.negative.fa'
    pos_matches = search_training_data(sequence_file, pos_training_file)
    neg_matches = search_training_data(sequence_file, neg_training_file)


# general functions

def besselFilter(data, cutoff, order=1, dt=None, btype='low', bidir=True):
    """return data passed through bessel filter"""

    if dt is None:
        dt = 1.0

    b,a = scipy.signal.bessel(order, cutoff * dt, btype=btype) 

    if bidir:
        d1 = scipy.signal.lfilter(b, a, scipy.signal.lfilter(b, a, data)[::-1])[::-1]
    else:
        d1 = scipy.signal.lfilter(b, a, data)

    return d1

def load_probabilities(file_name, quiet=False):
    if not quiet:
        print("Loading model output from %s" % file_name)
    import pickle
    with open(file_name, 'rb') as f:
        probs = pickle.load(f)
    return probs

